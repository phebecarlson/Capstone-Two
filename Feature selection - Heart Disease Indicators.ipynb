{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d208f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "%matplotlib inline\n",
    "import os\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "\n",
    "from dython.nominal import associations, numerical_encoding, cluster_correlations\n",
    "from dython.data_utils import split_hist\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import LassoCV, RidgeCV\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree \n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score, balanced_accuracy_score, classification_report, precision_recall_curve\n",
    "from sklearn.metrics import PrecisionRecallDisplay, average_precision_score, auc\n",
    "from sklearn_evaluation import plot, table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3865ede8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style='whitegrid', palette='pastel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cf2d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Capstone-Two/heartPHI2020.csv')\n",
    "df = data.copy()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f024a87",
   "metadata": {},
   "source": [
    "## Handling Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cd08cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample and undersample and look at distributions.\n",
    "# Undersample removes samples randomly from the majority class to make the distribution more equal\n",
    "# As usual, X is all minus target variable\n",
    "under_sampler = RandomUnderSampler(sampling_strategy=1, random_state=123)\n",
    "X = df.iloc[:, 1:]\n",
    "y = df['HeartDisease']\n",
    "X_under, y_under = under_sampler.fit_resample(X, y)\n",
    "\n",
    "# Count classes and create pie chart\n",
    "print(f'After undersampling: {Counter(y_under)}')\n",
    "plt.pie(y_under.value_counts(), labels = ['No', 'Yes'], autopct='%.0f%%');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f764394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampling randomly chooses and adds in samples from minority class to make distribution more equal\n",
    "over_sampler = RandomOverSampler(sampling_strategy='minority', random_state=123)\n",
    "X = df.iloc[:, 1:]\n",
    "y = df['HeartDisease']\n",
    "X_over, y_over = over_sampler.fit_resample(X, y)\n",
    "\n",
    "print(f'After oversampling: {Counter(y_over)}')\n",
    "plt.pie(y_over.value_counts(), labels = ['No', 'Yes'], autopct='%.0f%%');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3256cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will move forward with undersampled df and explore oversampled df model performance later\n",
    "y_under = pd.DataFrame(y_under)\n",
    "undersampled_df = y_under.merge(X_under, left_index=True, right_index=True)\n",
    "df = undersampled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a03e3a",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a00771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# people with MentalHealth or PhysicalHealth response of 0, \n",
    "# responded that they had mental and physical problems 0 out of the last 30 days\n",
    "df[['SleepTime', 'PhysicalHealth', 'MentalHealth']] = df[['SleepTime', 'PhysicalHealth', 'MentalHealth']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa8faff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar to this study - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4877313/\n",
    "# will evaluate, BMI PhysicalHealth, MentalHealth, and SleepTime as both continuous and categorical variables\n",
    "# they used these bins for SleepTime of ≤ 6 h, > 6 to < 9 h, ≥ 9 h\n",
    "# MentalHealth and PhysicalHealth variables are responses to how many days in last 30-31 were bad for health\n",
    "# binning them by week\n",
    "# Underweight: Less than 18.5, Healthy: 18.5 to 24.9, Overweight: 25 to 29.9, Class I obesity: 30 to 34.9, Class II obesity: 35 to 39.9, Class III obesity: More than 40.\n",
    "\n",
    "sleep_bins = [-np.inf, 5, 7, 9, np.inf]\n",
    "sleep_labels = ['≤ 5', '> 5 to ≤ 7 h', '> 7 to ≤ 9 h', '> 9 h']\n",
    "df['SleepTime_binned'] = pd.cut(df['SleepTime'], bins=sleep_bins, labels=sleep_labels)\n",
    "\n",
    "bmi_bins = [-np.inf, 18.49, 24.9, 29.9, 34.9, 39.9, np.inf]\n",
    "bmi_labels = ['Underweight','Healthy','Overweight', 'Class I Obesity', 'Class II Obesity', 'Class III Obesity']\n",
    "df['BMI_binned'] = pd.cut(df['BMI'], bins=bmi_bins, labels=bmi_labels)\n",
    "\n",
    "mental_bins = [-np.inf, 7, 14, 21, np.inf]\n",
    "mental_labels = ['≤ 7 days','8-14 days','15-21 days', '> 21 days']\n",
    "df['MentalHealth_binned'] = pd.cut(df['MentalHealth'], bins=mental_bins, labels=mental_labels)\n",
    "\n",
    "physical_bins = [-np.inf, 7, 14, 21, np.inf]\n",
    "physical_labels = ['≤ 7 days','8-14 days','15-21 days', '> 21 days']\n",
    "df['PhysicalHealth_binned'] = pd.cut(df['PhysicalHealth'], bins=physical_bins, labels=physical_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513ed881",
   "metadata": {},
   "outputs": [],
   "source": [
    "agecat_mean = {'18-24':21,'25-29':27,'30-34':32,'35-39':37,'40-44':42,'45-49':47,'50-54':52,'55-59':57, \n",
    "                    '60-64':62,'65-69':67,'70-74':72,'75-79':77,'80 or older':80}\n",
    "\n",
    "df['Mean_Age'] = df['AgeCategory'].apply(lambda x: agecat_mean[x])\n",
    "df.drop(columns=['AgeCategory'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a696add",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_covariance = df.cov()\n",
    "sns.heatmap(data_covariance, vmax=.8, square=True)\n",
    "plt.title(\"Covariance of Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1aa0fb",
   "metadata": {},
   "source": [
    "Encode and standardize data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2454d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encode cols with 2 or less options\n",
    "lencoder = LabelEncoder()\n",
    "columns = ['Sex', 'HeartDisease', 'Smoking', 'AlcoholDrinking', 'Stroke', 'DiffWalking', \n",
    "           'PhysicalActivity', 'Asthma', 'KidneyDisease', 'SkinCancer', 'PhysicalHealth']\n",
    "for col in columns:\n",
    "        df[col] = lencoder.fit_transform(df[col])\n",
    "# onehot encode variables nunique > 2 -- model accuracies lower with onehot encoded 'AgeCategory'\n",
    "df = pd.get_dummies(df, columns=['Race', 'Diabetic', 'GenHealth', 'SleepTime_binned', 'BMI_binned', 'MentalHealth_binned', \n",
    "                                 'PhysicalHealth_binned'], prefix=['Race', 'Diabetic', 'GenHealth', 'SleepTime_binned', \n",
    "                                                                   'BMI_binned', 'MentalHealth_binned', 'PhysicalHealth_binned'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2a1b3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_covariance = df.cov()\n",
    "sns.heatmap(data_covariance, vmax=.8, square=True)\n",
    "plt.title(\"Covariance of Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec35ab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split (before scaler)\n",
    "X = df.iloc[:, 1:]\n",
    "y = df['HeartDisease']\n",
    "\n",
    "# confirm balance\n",
    "sns.countplot(x=y, data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021a3dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbab6e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_corr = df.corr()['HeartDisease'].abs().sort_values(ascending=False)\n",
    "df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae148c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train/test before scaling or tuning to avoid data leakage\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c7f4ba",
   "metadata": {},
   "source": [
    "Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747d42f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier detection\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "lof = LocalOutlierFactor(p=1, n_jobs=-1)\n",
    "yhat = lof.fit_predict(X_train)\n",
    "# select all rows that are not outliers -- -1 is outlier \n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train.iloc[mask], y_train.iloc[mask]\n",
    "# summarize the shape of the updated training dataset\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7676a0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_removed = len(yhat) - np.count_nonzero(yhat==1)\n",
    "num_removed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7594f613",
   "metadata": {},
   "source": [
    "Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26a021a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate numerical columns to be scaled\n",
    "num_train_df = X_train[['BMI', 'PhysicalHealth','MentalHealth', 'SleepTime', 'Mean_Age']]\n",
    "num_test_df = X_test[['BMI', 'PhysicalHealth', 'MentalHealth', 'SleepTime', 'Mean_Age']]\n",
    "\n",
    "# fit scaler on training data and only transform test data\n",
    "# scale after train_test_split to avoid causing data leakage\n",
    "scaler = RobustScaler()\n",
    "\n",
    "X_train_num = scaler.fit(num_train_df)\n",
    "X_train_num = scaler.transform(num_train_df)\n",
    "X_test_num = scaler.transform(num_test_df)\n",
    "\n",
    "# Add column names and convert to df\n",
    "col_names = ['BMI', 'PhysicalHealth', 'MentalHealth', 'SleepTime', 'Mean_Age']\n",
    "X_train_num = pd.DataFrame(X_train_num, columns=col_names)\n",
    "X_test_num = pd.DataFrame(X_test_num, columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9346c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge cat and num dataframes\n",
    "X_train = X_train.drop(columns=['BMI', 'PhysicalHealth', 'MentalHealth', 'SleepTime', 'Mean_Age'])\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_train = X_train.merge(X_train_num, left_index=True, right_index=True)\n",
    "\n",
    "X_test = X_test.drop(columns=['BMI', 'PhysicalHealth', 'MentalHealth', 'SleepTime', 'Mean_Age'])\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "X_test = X_test.merge(X_test_num, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054734bd",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8091ff2e",
   "metadata": {},
   "source": [
    "Tested LassoCV, RidgeCV, RFECV, and models selection methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2ee850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection with lasso regularization \n",
    "alphas = np.arange(0.1,10,0.1)\n",
    "lassocv = LassoCV(alphas=alphas, random_state = 45)\n",
    "lassocv.fit(X_train, y_train)\n",
    "\n",
    "print(f'lassocv coef > 0 : {np.sum(lassocv.coef_ > 0)}')\n",
    "feature_names = lassocv.feature_names_in_[lassocv.coef_ > 0]\n",
    "print(f'features with lassocv coef > 0: {feature_names}')\n",
    "print(f'alpha: {lassocv.alpha_}')\n",
    "lasso_mse_path = lassocv.mse_path_\n",
    "print(f'num features in: {lassocv.n_features_in_}')\n",
    "print(f'score: {lassocv.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd43493",
   "metadata": {},
   "source": [
    "After substituting mean_age for AgeCategory, Lasso suggests 2 features: ['PhysicalHealth' 'Mean_Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce64995",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# feature selection with RidgeCV \n",
    "ridgecv = RidgeCV(alphas=alphas)\n",
    "ridgecv.fit(X_train, y_train)\n",
    "\n",
    "print(f'ridgecv coef > 0 : {np.sum(ridgecv.coef_ > 0)}')\n",
    "sorted_coef = pd.Series(ridgecv.coef_).sort_values(ascending=False)\n",
    "feature_names = ridgecv.feature_names_in_[sorted_coef.index]\n",
    "print(f'sorted order (large to small) of ridgecv coef > 0: \\n{feature_names}')\n",
    "print(f'num features in: {ridgecv.n_features_in_}')\n",
    "print(f'score: {ridgecv.score(X_test,y_test)}')\n",
    "print(f'best score: {ridgecv.best_score_}')\n",
    "magnitude_order_series = pd.Series(np.abs(list(ridgecv.coef_))).sort_values(ascending=False)\n",
    "idx = magnitude_order_series.index\n",
    "magnitude_order = ridgecv.feature_names_in_[idx]\n",
    "print(f'top 20 magnitude order of abs(ridgecv coef) > 0: \\n{magnitude_order[0:20]}')\n",
    "print(f'bottom 10 magnitude order of abs(ridgecv coef) > 0: \\n{magnitude_order[-21:-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef79add8",
   "metadata": {},
   "source": [
    "## Features groupings to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8c5618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean_Age only\n",
    "age_X_train = X_train[['Mean_Age']]\n",
    "age_X_test = X_test[['Mean_Age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26dc2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso chosen features\n",
    "lasso_X_train = X_train[['Mean_Age', 'PhysicalHealth']]\n",
    "lasso_X_test = X_test[['Mean_Age', 'PhysicalHealth']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8a0300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFECV features\n",
    "RFElr_X_train = X_train[['Smoking', 'AlcoholDrinking', 'Stroke', 'DiffWalking', 'Sex', 'Asthma',\n",
    "       'KidneyDisease', 'SkinCancer', 'Race_Asian', 'Race_Black', 'Race_White',\n",
    "       'Diabetic_No', 'Diabetic_Yes', 'GenHealth_Excellent', 'GenHealth_Fair',\n",
    "       'GenHealth_Poor', 'GenHealth_Very good',\n",
    "       'SleepTime_binned_> 5 to ≤ 7 h', 'SleepTime_binned_> 7 to ≤ 9 h',\n",
    "       'BMI_binned_Healthy', 'BMI_binned_Class I Obesity',\n",
    "       'MentalHealth_binned_≤ 7 days', 'PhysicalHealth_binned_≤ 7 days', 'BMI',\n",
    "       'SleepTime', 'Mean_Age']]\n",
    "RFElr_X_test = X_test[['Smoking', 'AlcoholDrinking', 'Stroke', 'DiffWalking', 'Sex', 'Asthma',\n",
    "       'KidneyDisease', 'SkinCancer', 'Race_Asian', 'Race_Black', 'Race_White',\n",
    "       'Diabetic_No', 'Diabetic_Yes', 'GenHealth_Excellent', 'GenHealth_Fair',\n",
    "       'GenHealth_Poor', 'GenHealth_Very good',\n",
    "       'SleepTime_binned_> 5 to ≤ 7 h', 'SleepTime_binned_> 7 to ≤ 9 h',\n",
    "       'BMI_binned_Healthy', 'BMI_binned_Class I Obesity',\n",
    "       'MentalHealth_binned_≤ 7 days', 'PhysicalHealth_binned_≤ 7 days', 'BMI',\n",
    "       'SleepTime', 'Mean_Age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fc610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Reg Lasso model chosen features\n",
    "lowzeroimportance_features = ['Race_White', 'BMI_binned_Class I Obesity','PhysicalActivity','PhysicalHealth', 'BMI_binned_Overweight',\n",
    "                 'SleepTime_binned_≤ 5','MentalHealth_binned_> 21 days', 'MentalHealth_binned_15-21 days', 'PhysicalHealth_binned_8-14 days',\n",
    "                 'MentalHealth_binned_8-14 days','PhysicalHealth_binned_> 21 days','SleepTime_binned_> 9 h','BMI',\n",
    "                 'Race_Other','BMI_binned_Class III Obesity','BMI_binned_Class II Obesity','Race_Hispanic','BMI_binned_Underweight',\n",
    "                 'MentalHealth','Race_American Indian/Alaskan Native','GenHealth_Good','Diabetic_Yes (during pregnancy)',\n",
    "                 'Diabetic_No, borderline diabetes','PhysicalHealth_binned_15-21 days','BMI_binned_Healthy']\n",
    "d_train = X_train.copy()\n",
    "d_test = X_test.copy()\n",
    "important_X_train = d_train.drop(columns=lowzeroimportance_features)\n",
    "important_X_test = d_test.drop(columns=lowzeroimportance_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa1d8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_X_train = X_train[['Stroke', 'DiffWalking', 'Sex', 'Diabetic_No', 'Diabetic_Yes',\n",
    "                       'GenHealth_Excellent', 'GenHealth_Fair', 'GenHealth_Good', \n",
    "                       'GenHealth_Poor', 'GenHealth_Very good', 'Mean_Age']]\n",
    "xgb_X_test = X_test[['Stroke', 'DiffWalking', 'Sex', 'Diabetic_No', 'Diabetic_Yes',\n",
    "                      'GenHealth_Excellent', 'GenHealth_Fair', 'GenHealth_Good',\n",
    "                      'GenHealth_Poor', 'GenHealth_Very good', 'Mean_Age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708c9c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest selected features\n",
    "rf_15_train = X_train[['Mean_Age', 'DiffWalking', 'GenHealth_Excellent',\n",
    "                        'PhysicalHealth', 'Stroke', 'Diabetic_Yes', 'BMI',\n",
    "                        'Diabetic_No', 'GenHealth_Fair', 'Sex', 'PhysicalHealth_binned_≤ 7 days',\n",
    "                       'GenHealth_Very good', 'Smoking', 'GenHealth_Poor', 'MentalHealth']]\n",
    "rf_15_test = X_test[['Mean_Age', 'DiffWalking', 'GenHealth_Excellent',\n",
    "                        'PhysicalHealth', 'Stroke', 'Diabetic_Yes', 'BMI',\n",
    "                        'Diabetic_No', 'GenHealth_Fair', 'Sex', 'PhysicalHealth_binned_≤ 7 days',\n",
    "                     'GenHealth_Very good', 'Smoking', 'GenHealth_Poor', 'MentalHealth']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d63f077",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4e5c69",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eec2f9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# out of the box logistic regression model for benchmark\n",
    "# starting off simple with a linear model - LogReg\n",
    "lr = LogisticRegression(random_state=123, max_iter=300)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print('LogReg1 no penalty model: \\n')\n",
    "print(f'Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}')\n",
    "print(f'Classification report: \\n{classification_report(y_test, y_pred, digits=5)}')\n",
    "\n",
    "y_hat = lr.predict(X_train)\n",
    "print(f'LogReg training set accuracy: {accuracy_score(y_train, y_hat)}')\n",
    "print(f'LogReg test set accuracy: {accuracy_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae1823e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression with l1 regularization (Lasso) \n",
    "lr2 = LogisticRegressionCV(Cs=10, penalty='l1', solver='liblinear', scoring='accuracy', cv=StratifiedKFold(5), random_state=45, n_jobs=-1)\n",
    "lr2 = lr2.fit(X_train, y_train)\n",
    "y_pred2 = lr2.predict(X_test)\n",
    "\n",
    "print('LogReg2 Lasso model: \\n')\n",
    "print(f'Confusion matrix: \\n{confusion_matrix(y_test, y_pred2)}\\n')\n",
    "print(f'Classification report: \\n{classification_report(y_test, y_pred2, digits=5)}')\n",
    "\n",
    "# model evaluation against test set\n",
    "y_hat = lr2.predict(X_train)\n",
    "print(f'LogReg2 training set accuracy: {accuracy_score(y_train, y_hat)}')\n",
    "print(f'LogReg2 test set accuracy: {accuracy_score(y_test, y_pred2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630e587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used RFECV to compute best iterations of 20 and 25 features, \n",
    "# then using cross-validation. Did not come up with higher accuracy models\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "simplefilter(action='ignore', category='UndefinedMetricWarning')\n",
    "\n",
    "#lr2 = LogisticRegressionCV(Cs=10, penalty='l1', solver='liblinear', scoring='precision', cv=5, random_state=45)\n",
    "min_features_to_select=1\n",
    "rfecv = RFECV(lr2, min_features_to_select=min_features_to_select, step=1, cv=StratifiedKFold(5),\n",
    "    scoring='accuracy', n_jobs=-1)\n",
    "rfecv.fit(X_train, y_train)\n",
    "rfecv_feature_names_out = rfecv.get_feature_names_out()\n",
    "status = rfecv.support_\n",
    "rankings = rfecv.ranking_\n",
    "best_features =  X_train[rfecv_feature_names_out]\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "print(f'RFE selected features: \\n{best_features.columns}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7971a183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot RFECV cv_scores_\n",
    "plt.figure()\n",
    "plt.title('Recursive Feature Elimination Results for Log Reg Lasso', fontsize=20)\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (accuracy)\")\n",
    "plt.plot(range(min_features_to_select, \n",
    "               (len(rfecv.cv_results_['mean_test_score']) + min_features_to_select)),\n",
    "         rfecv.cv_results_['mean_test_score'],)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb3b406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot \n",
    "plt.figure(figsize=(12,7))\n",
    "plt.title('Recursive Feature Elimination Results for Log Reg Lasso', fontsize=20)\n",
    "plt.xlabel('Number of features selected')\n",
    "plt.ylabel('Cross validation score (nb of correct classifications)')\n",
    "plt.plot(range(1, len(rfecv.cv_results_['mean_test_score']) + 1), rfecv.cv_results_['mean_test_score'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8a03f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature coefficients representing feature importance\n",
    "feature_names = list(lr2.feature_names_in_)\n",
    "coef_ = lr2.coef_[0]\n",
    "coef = pd.Series(coef_, feature_names)\n",
    "fig, ax = plt.subplots(1,2,figsize=(20,6))\n",
    "coef.sort_values().plot(kind='bar', title='Feature Coefficients', ax=ax[0])\n",
    "\n",
    "# plot absolute value of coefficients \n",
    "# according to scikit documentation, model.coef_[0] is used to get the importance of the feature.\n",
    "plot.feature_importances(coef_, top_n=8, feature_names=feature_names, ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf845d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot feature coefficients representing feature importance -- after scaling/correcting with standard deviation\n",
    "feature_names = list(lr2.feature_names_in_)\n",
    "coef_ = lr2.coef_[0]\n",
    "coef = pd.Series(coef_* X_train.std(axis=0), feature_names)\n",
    "fig, ax = plt.subplots(1,2,figsize=(20,6))\n",
    "plt.suptitle(\"Logistic Regression Model with Lasso Regularization\")\n",
    "coef.sort_values().plot(kind='bar', title=\"Feature Coefficients Corrected by Each Feature's Standard Deviation\", ax=ax[0])\n",
    "\n",
    "# plot absolute value of coefficients \n",
    "# according to scikit documentation, model.coef_[0] is used to get the importance of the feature.\n",
    "feature_importances = pd.DataFrame(coef_ * X_train.std(axis=0), columns=[\"Coefficient importance\"],index=feature_names)\n",
    "\n",
    "plot.feature_importances(coef_* X_train.std(axis=0), top_n=15, feature_names=feature_names, ax=ax[1])\n",
    "plt.title(\"Feature Importance Corrected by Each Feature's Standard Deviation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19ba652",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot coefs after scaling with standard deviation\n",
    "coefs = pd.DataFrame(coef_ * X_train.std(axis=0), columns=[\"Coefficient importance\"],index=feature_names)\n",
    "coefs.plot(kind=\"barh\", figsize=(15, 7))\n",
    "plt.xlabel(\"Coefficient values corrected by the feature's std. dev.\")\n",
    "plt.title(\"Ridge model, small regularization\")\n",
    "plt.axvline(x=0, color=\".5\")\n",
    "plt.subplots_adjust(left=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1a83ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_importances = feature_importances.sort_values(by='Coefficient importance', ascending=False)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb7eef4",
   "metadata": {},
   "source": [
    "**Begin testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc00d42a",
   "metadata": {},
   "source": [
    "Test selected feature groupings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eb303f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features selected by RFE \n",
    "# LogReg model with lasso regularization (Lasso) \n",
    "rfelr = LogisticRegressionCV(Cs=10, penalty='l1', solver='liblinear', scoring='accuracy', cv=StratifiedKFold(5), random_state=45, n_jobs=-1)\n",
    "rfelr = rfelr.fit(RFElr_X_train, y_train)\n",
    "rfey_pred = rfelr.predict(RFElr_X_test)\n",
    "\n",
    "print('LogReg2 Lasso model: \\n')\n",
    "print(f'Confusion matrix: \\n{confusion_matrix(y_test, rfey_pred)}\\n')\n",
    "print(f'Classification report: \\n{classification_report(y_test, rfey_pred, digits=5)}')\n",
    "\n",
    "# model evaluation against test set\n",
    "rfey_hat = rfelr.predict(RFElr_X_train)\n",
    "print(f'LogReg2 training set accuracy: {accuracy_score(y_train, rfey_hat)}')\n",
    "print(f'LogReg2 test set accuracy: {accuracy_score(y_test, rfey_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc95d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features selected by LogReg model \n",
    "# LogReg model with lasso regularization \n",
    "lr_zerolow = LogisticRegression(penalty='l1', solver='liblinear', random_state=45)\n",
    "lr_zerolow = lr_zerolow.fit(important_X_train, y_train)\n",
    "y_pred_zerolow = lr_zerolow.predict(important_X_test)\n",
    "\n",
    "print('Important Features Only LogReg model: \\n')\n",
    "print(f'Confusion matrix: \\n{confusion_matrix(y_test, y_pred_zerolow)}\\n')\n",
    "print(f'Classification report: \\n{classification_report(y_test, y_pred_zerolow, digits=5)}')\n",
    "\n",
    "# model evaluation against test set\n",
    "y_ha_zerolowt = lr_zerolow.predict(important_X_train)\n",
    "print(f'Lasso Features Only training set accuracy: {accuracy_score(y_train, y_hat)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85ea2c0",
   "metadata": {},
   "source": [
    "**Mean_Age Only Log Reg!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be717f31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# AGE ONLY Logistic Regression with l1 regularization (Lasso) \n",
    "lr2_age = LogisticRegressionCV(Cs=10, penalty='l1', solver='liblinear', scoring='accuracy', cv=StratifiedKFold(5), random_state=45, n_jobs=-1)\n",
    "lr2_age = lr2_age.fit(age_X_train, y_train)\n",
    "y_pred2_age = lr2_age.predict(age_X_test)\n",
    "\n",
    "print('Mean_Age Only LogReg2 Lasso model: \\n')\n",
    "print(f'Confusion matrix: \\n{confusion_matrix(y_test, y_pred2_age)}\\n')\n",
    "print(f'Classification report: \\n{classification_report(y_test, y_pred2_age, digits=5)}')\n",
    "\n",
    "# model evaluation against test set\n",
    "y_hat_age = lr2_age.predict(age_X_train)\n",
    "print(f'Mean_Age Only LogReg2 training set accuracy: {accuracy_score(y_train, y_hat_age)}')\n",
    "print(f'Mean_Age Only LogReg2 test set accuracy: {accuracy_score(y_test, y_pred2_age)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6b2c30",
   "metadata": {},
   "source": [
    "PhysicalHealth, Mean_Age Only LogReg2 training set accuracy: 0.7251364053805845\n",
    "PhysicalHealth, Mean_Age Only LogReg2 test set accuracy: 0.712054794520548"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6c3a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2_age_prob = lr2_age.predict_proba(age_X_test)\n",
    "y_pred2_age_proba = [j for [i,j] in y_pred2_age_prob]\n",
    "age_roc_pred = RocCurveDisplay.from_predictions(y_test, y_pred2_age_proba)\n",
    "plt.title(\"Mean_Age Only Only RoC Curve\")\n",
    "plt.show()\n",
    "\n",
    "ras = roc_auc_score(y_test, y_pred2_age_proba)\n",
    "print(f\"Mean_Age Only only ROC-AUC: {ras}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f4e014",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision = average_precision_score(y_test, y_pred2_age_proba, average=\"micro\", pos_label=1)\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred2_age_proba, pos_label=1)\n",
    "disp = PrecisionRecallDisplay(precision=precision, recall=recall, average_precision=average_precision, estimator_name=\"lr2_age\")\n",
    "disp.plot()\n",
    "plt.title(\"Mean_Age Only Only: Precision-Recall\")\n",
    "plt.show()\n",
    "pr_auc = average_precision_score(y_test, y_pred2_age_proba, pos_label=1)\n",
    "print(f\"Mean_Age Only Only Precision-Recall AUC: {pr_auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52288e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test other models with feature selection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4ac856",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bd5432",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = {'criterion' : ['gini', 'entropy'],\n",
    "               'n_estimators' : list(range(1,500)),\n",
    "               'max_depth': list(range(3, 20))}\n",
    "\n",
    "rf_rs = RandomizedSearchCV(RandomForestClassifier(), grid_params, verbose=1, cv=5, n_jobs=-1)\n",
    "rf = rf_rs.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best params: {rf.best_params_}')\n",
    "print(f'Best score: {rf.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8ed065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entropy Random Forest Classifier model, consider playing with max_depth. is that a hyperparameter?\n",
    "rfc = RandomForestClassifier(criterion='entropy', n_estimators=362, max_depth=12, n_jobs=-1)\n",
    "rfc.fit(X_train, y_train)\n",
    "y_pred_rfc = rfc.predict(X_test)\n",
    "\n",
    "print('Random Forest Entropy model \\n')\n",
    "print(f'Confusion matrix: \\n {confusion_matrix(y_test,y_pred_rfc)}\\n')\n",
    "print(f'Classification report: \\n{classification_report(y_test, y_pred_rfc, digits=5)}')\n",
    "\n",
    "# model evaluation against test set\n",
    "y_hat = rfc.predict(X_train)\n",
    "print(f'Random Forest training set accuracy: {accuracy_score(y_train, y_hat)}')\n",
    "print(f'Random Forest test set accuracy: {accuracy_score(y_test, y_pred_rfc)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626b1b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot RandomForestClassifier feature importances\n",
    "feature_names = list(rfc.feature_names_in_)\n",
    "feature_importances = rfc.feature_importances_\n",
    "plot.feature_importances(feature_importances, top_n=15, feature_names=feature_names)\n",
    "plt.title('Random Forest Feature Importances')\n",
    "plt.show()\n",
    "# table of importances\n",
    "table.feature_importances(feature_importances, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae15625",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(rfc.feature_names_in_)\n",
    "importances = rfc.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.title('Random Forest Feature Importances')\n",
    "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "plt.xlabel('Random Forest Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861a7d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest selected features\n",
    "rf_15_train = X_train[['Mean_Age', 'DiffWalking', 'GenHealth_Excellent',\n",
    "                        'PhysicalHealth', 'Stroke', 'Diabetic_Yes', 'BMI',\n",
    "                        'Diabetic_No', 'GenHealth_Fair', 'Sex', 'PhysicalHealth_binned_≤ 7 days',\n",
    "                       'GenHealth_Very good', 'Smoking', 'GenHealth_Poor', 'MentalHealth']]\n",
    "rf_15_test = X_test[['Mean_Age', 'DiffWalking', 'GenHealth_Excellent',\n",
    "                        'PhysicalHealth', 'Stroke', 'Diabetic_Yes', 'BMI',\n",
    "                        'Diabetic_No', 'GenHealth_Fair', 'Sex', 'PhysicalHealth_binned_≤ 7 days',\n",
    "                     'GenHealth_Very good', 'Smoking', 'GenHealth_Poor', 'MentalHealth']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac03b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_15 = RandomForestClassifier(criterion='entropy', n_estimators=362, max_depth=12, n_jobs=-1)\n",
    "rfc_15.fit(rf_15_train, y_train)\n",
    "y_pred_rfc_15 = rfc_15.predict(rf_15_test)\n",
    "\n",
    "print('Random Forest Entropy model \\n')\n",
    "print(f'Confusion matrix: \\n {confusion_matrix(y_test,y_pred_rfc_15)}\\n')\n",
    "print(f'Classification report: \\n{classification_report(y_test, y_pred_rfc_15, digits=5)}')\n",
    "\n",
    "# model evaluation against test set\n",
    "y_hat_15 = rfc_15.predict(rf_15_train)\n",
    "print(f'Random Forest training set accuracy: {accuracy_score(y_train, y_hat_15)}')\n",
    "print(f'Random Forest test set accuracy: {accuracy_score(y_test, y_pred_rfc_15)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41f965b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do I need to multiply through by standard deviation for feature importances?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc7802f",
   "metadata": {},
   "source": [
    "**XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2dbf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "xgb = XGBClassifier(use_label_encoder=False, random_state=123)\n",
    "xgb = xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "# evaluate xgb model\n",
    "print('XGBoost model: \\n')\n",
    "print(f'Confusion matrix: \\n {confusion_matrix(y_test,y_pred_xgb)}\\n')\n",
    "print(f'Classification report: \\n{classification_report(y_test, y_pred_xgb, digits=5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ebcbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB model evaluation against test set\n",
    "y_hat = xgb.predict(X_train)\n",
    "print(f'XGB training set accuracy: {accuracy_score(y_train, y_hat)}')\n",
    "print(f'XGB test set accuracy: {accuracy_score(y_test, y_pred_xgb)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57175399",
   "metadata": {},
   "source": [
    "XGB may be overfit with a higher training set accuracy than test set accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3251a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used RFECV to compute best XGB feature iterations\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "min_features_to_select=1\n",
    "xgb_rfecv = RFECV(xgb, min_features_to_select=min_features_to_select, step=1, cv=StratifiedKFold(5),\n",
    "    scoring='accuracy', n_jobs=-1)\n",
    "xgb_rfecv.fit(X_train, y_train)\n",
    "xgb_rfecv_feature_names_out = xgb_rfecv.get_feature_names_out()\n",
    "xgb_status = xgb_rfecv.support_\n",
    "xgb_rankings = xgb_rfecv.ranking_\n",
    "xgb_best_features =  X_train[xgb_rfecv_feature_names_out]\n",
    "print(\"XGB Optimal number of features : %d\" % xgb_rfecv.n_features_)\n",
    "print(f'XGB RFE selected features: \\n{xgb_best_features.columns}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7802b07d",
   "metadata": {},
   "source": [
    "XGB RFECV chosen features:\n",
    "\n",
    "Optimal number of features : 11\n",
    "RFE selected features: \n",
    "Index(['Stroke', 'DiffWalking', 'Sex', 'Diabetic_No', 'Diabetic_Yes',\n",
    "       'GenHealth_Excellent', 'GenHealth_Fair', 'GenHealth_Good',\n",
    "       'GenHealth_Poor', 'GenHealth_Very good', 'Mean_Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230ba45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot XGB RFECV cv_scores_\n",
    "plt.figure()\n",
    "plt.title('XGB Recursive Feature Elimination')\n",
    "plt.xlabel('Number of features selected')\n",
    "plt.ylabel('Cross validation score (accuracy)')\n",
    "plt.plot(range(min_features_to_select, \n",
    "               (len(xgb_rfecv.cv_results_['mean_test_score']) + min_features_to_select)),\n",
    "         xgb_rfecv.cv_results_['mean_test_score'],)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43af6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "_ = plt.title('Recursive Feature Elimination Results for XGBoost', fontsize=20)\n",
    "_ = plt.xlabel('Number of features selected')\n",
    "_ = plt.ylabel('Cross validation score (nb of correct classifications)')\n",
    "_ = plt.plot(range(1, len(rfecv.cv_results_['mean_test_score']) + 1), rfecv.cv_results_['mean_test_score'])\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fb0feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_X_train = X_train[['Stroke', 'DiffWalking', 'Sex', 'Diabetic_No', 'Diabetic_Yes',\n",
    "                       'GenHealth_Excellent', 'GenHealth_Fair', 'GenHealth_Good', \n",
    "                       'GenHealth_Poor', 'GenHealth_Very good', 'Mean_Age']]\n",
    "xgb_X_test = X_test[['Stroke', 'DiffWalking', 'Sex', 'Diabetic_No', 'Diabetic_Yes',\n",
    "                      'GenHealth_Excellent', 'GenHealth_Fair', 'GenHealth_Good',\n",
    "                      'GenHealth_Poor', 'GenHealth_Very good', 'Mean_Age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e60163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost using selected XGB features\n",
    "xgb2 = XGBClassifier(use_label_encoder=False, random_state=123)\n",
    "xgb2 = xgb2.fit(xgb_X_train, y_train)\n",
    "y_pred_xgb2 = xgb2.predict(xgb_X_test)\n",
    "\n",
    "# evaluate xgb2 model\n",
    "print('XGBoost model with Selected Features: \\n')\n",
    "print(f'Confusion matrix: \\n {confusion_matrix(y_test,y_pred_xgb2)}\\n')\n",
    "print(f'Classification report: \\n{classification_report(y_test, y_pred_xgb2, digits=5)}')\n",
    "\n",
    "\n",
    "# model evaluation against test set\n",
    "xgb2_y_hat = xgb2.predict(xgb_X_train)\n",
    "print(f'XGB2 training set accuracy: {accuracy_score(y_train, xgb2_y_hat)}')\n",
    "print(f'XGB2 Forest test set accuracy: {accuracy_score(y_test, y_pred_xgb2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6d96ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using XGB selected features limits overfitting on the training set \n",
    "# and increases accuracy somewhat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
